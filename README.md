#  FL_EZKL

Our project focuses on federated learning, leveraging zero-knowledge (zk) proofs to verify the integrity of model weights trained from a public model.
This approach enhances data privacy by allowing secure verification without direct access to the data, ensuring accurate and trustworthy model updates across distributed systems.

## Team Information

- **Project Members:**

  - **Name**: Nguyen Hoai Duy
    - **Discord Username**: nguyenhoaiduy0
    - **Devfolio Username**: nguyenhoaiduy0
    - **GitHub Username**: DarkMacician
    - **Role**: Leader
  
  - **Name**: Huynh Van Dong
      - **Discord Username**: donghuynh0
      - **Devfolio Username**: donghuynh0
      - **GitHub Username**: donghuynh0
      - **Role**: Member
        
  - **Name**: Vo Huu Nhan 
    - **Discord Username**: nhanvp
    - **Devfolio Username**: nhanvp
    - **GitHub Username**: louisdevzz
    - **Role**: Member
        
## Technical Approach

- **Components**:
  - ZK Circuits
  - Machine Learning (ML)

## What do you plan to achieve with your project?

Our project aims to enhance the security and transparency of federated learning models by integrating zero-knowledge (zk) proofs for weight verification.
This approach will allow for decentralized, privacy-preserving machine learning while ensuring the integrity of model updates across distributed systems.
In the future, we plan to improve the zk-proof mechanisms to make them more efficient and scalable, allowing our solution to support larger datasets and more complex models

## Lessons Learned 

- **Key Takeaways**: We learned how to effectively combine federated learning with zero-knowledge (zk) proofs to enhance privacy and security. Optimizing zk mechanisms for efficiency was essential for smooth model training.

## Project Links 
github link: https://github.com/DarkMacician/IG2024
## Video Demo 
https://drive.google.com/file/d/1uOwAvyNK5IKmB_BRHj-b-ktfb5J_rALb/view?usp=sharing
